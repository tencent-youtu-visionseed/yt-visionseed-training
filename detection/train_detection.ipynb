{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://visionseed.youtu.qq.com/docs/assets/markdown-img-hw-a.jpg\">\n",
    "\n",
    "这篇教程将指导你一步步配置环境、训练模型并将模型部署在VisionSeed上\n",
    "\n",
    "# 环境配置\n",
    "## 下载代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://gitee.com/charllechen/yolov3.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进入工作文件夹。注：每次**\"Restart Kernel\"**之后都需要重新运行下面的代码进入文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd yolov3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载依赖库\n",
    "### pip 依赖库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt -i https://mirrors.cloud.tencent.com/pypi/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置PyTorch 1.6.0环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://yolov3-1259675134.cos.ap-shanghai.myqcloud.com/torch-1.6.0%2Bcu101-cp37-cp37m-linux_x86_64.whl\n",
    "!pip install torch-1.6.0+cu101-cp37-cp37m-linux_x86_64.whl\n",
    "!pip install torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果返回True并且torch的版本为1.6.0+cu101，则说明安装好了\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "!pip show torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载MS COCO 2017数据库\n",
    "下载大概需要20分钟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir ../coco/images -p\n",
    "!wget https://yolov3-1259675134.cos.ap-shanghai.myqcloud.com/train2017.zip\n",
    "!unzip -q train2017.zip -d ../coco/images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下载标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://yolov3-1259675134.cos.ap-shanghai.myqcloud.com/annotations_trainval2017.zip\n",
    "!unzip -q annotations_trainval2017.zip -d ../coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除压缩包[可选]\n",
    "!rm annotations_trainval2017.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置标签\n",
    "因为训练代码要求标签文件以txt文件的形式存储在一个文件夹中，与图片的文件夹存储在同一个目录下（标签命名为labels，训练图片命名为images)。并且，除了后缀之外，标签的文件名需要与图片的一致\n",
    "\n",
    "目录例子\n",
    "- coco\n",
    "    - images\n",
    "        - test.jpg\n",
    "    - labels\n",
    "        - test.txt\n",
    "\n",
    "因此，我们需要运行下面的脚本来改变标签的形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out 设置为标签保存的文件夹，文件夹名称可以按需更改\n",
    "# image_folder 训练图片的文件夹，保持为默认即可\n",
    "# json 图片标注信息的json，保持为默认即可\n",
    "# cls 用于训练的标签种类，可以按需更改，不同类别用逗号隔开（逗号后不要留空格）。具体的标签信息可以参考data/coco.yaml下的names\n",
    "\n",
    "!python ./utils/coco.py --out ../coco/train_person_dog_cat --image_folder ../coco/images/train2017 --json ../coco/annotations/instances_train2017.json  --cls person,cat,dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机选择训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "# 标签的文件夹，应该与上一个cell中的out相同\n",
    "folder = '../coco/train_person_dog_cat'\n",
    "TRAIN_PER = 0.99 # 训练集和验证集的比例\n",
    "files = os.listdir(folder)\n",
    "files = [f for f in files if f.endswith('.jpg')]\n",
    "print(files[0])\n",
    "print(\"[total dataset size]:\", len(files))\n",
    "random.shuffle(files)\n",
    "cut = int(TRAIN_PER * len(files))\n",
    "with open(f'{folder}/train.txt', 'w') as f:\n",
    "    for img in files[:cut]:\n",
    "        f.write(f\"{folder}/{img}\\n\")\n",
    "with open(f'{folder}/val.txt', 'w') as f:\n",
    "    for img in files[cut:]:\n",
    "        f.write(f\"{folder}/{img}\\n\")\n",
    "print(f\"Train annotations saved at {folder}/train.txt\")\n",
    "print(f\"Val annotations saved at {folder}/val.txt\")\n",
    "print(\"[Train set size]: \", cut)\n",
    "print(\"[Val set size]: \", len(files) - cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**同时**，我们需要修改一下data/coco.yaml中train和val两个值（13和14行），让他们指向我们刚刚生成的train.txt和val.txt  \n",
    "![change coco yaml](https://yolov3-1259675134.cos.ap-shanghai.myqcloud.com/change_coco_yaml.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载预训练模型\n",
    "!wget https://yolov3-1259675134.cos.ap-shanghai.myqcloud.com/yolov3-tiny.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练\n",
    "接下来我们可以训练了！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/conda/envs/pytorch_py3/lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python train.py --data coco.yaml --weights yolov3-tiny.pt --epochs 100 --batch-size 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练好的结果会保存在./runs/train/的文件夹中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 二次训练：需要将weights对应的值改为相应的上次训练的pt文件\n",
    "!python train.py --data coco.yaml --weights ./runs/train/exp/weights/last.pt --epochs 1 --batch-size 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型转换\n",
    "下载依赖库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://yolov3-1259675134.cos.ap-shanghai.myqcloud.com/vstk.tar.gz\n",
    "!tar xzf vstk.tar.gz\n",
    "!rm vstk.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!sudo yum -y install protobuf-devel leveldb-devel snappy-devel opencv-devel boost-python36-devel hdf5-devel\n",
    "!sudo yum -y install gflags-devel glog-devel lmdb-devel\n",
    "!sudo yum -y install openblas-devel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install onnx termcolor onnxruntime scikit-image==0.15.0 networkx==2.0 opencv-python -i https://mirrors.cloud.tencent.com/pypi/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始模型转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir conversion conversion/orig conversion/stage conversion/final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义常量\n",
    "import os\n",
    "trained_model = './runs/train/exp/weights/best.pt' # 想要转换的pt模型的路径\n",
    "ORIG = './conversion/orig'\n",
    "STAGE = './conversion/stage'\n",
    "FINAL = './conversion/final'\n",
    "\n",
    "IMG = './conversion/orig/input.png' # 用于测试的图片，保持默认即可\n",
    "\n",
    "model_name = 'person_dog_cat.onnx' # 模型名称（请以.onnx结尾）\n",
    "TARGET = os.path.join(FINAL, 'custom_'+model_name).replace('onnx', 'blob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将pt模型转换为onnx模型\n",
    "from models.export import pt2onnx\n",
    "pt2onnx(trained_model, [288, 512])\n",
    "trained_onnx = trained_model.replace('pt', 'onnx')\n",
    "print('convert pt to onnx at', trained_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 初始化vstk\n",
    "import os\n",
    "os.sys.path.append('/home/tione/notebook/yolov3/vstk/onnx2caffe')\n",
    "from vstk import surgery, onnxToCaffe, generateBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将模型从训练环境复制到模型转换环境\n",
    "from shutil import copyfile\n",
    "\n",
    "orig_onnx = os.path.join(ORIG, model_name)\n",
    "copyfile(trained_onnx, orig_onnx)\n",
    "print(f\"copy {trained_onnx} to {orig_onnx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 对模型进行裁剪\n",
    "CUT = [88, 106, 52, 85] # 需要裁剪的层数\n",
    "OUTPUT_LAYER = [87] # 定义输出层\n",
    "ACT = \"sigmoid\" # 定义最后一层的激活函数\n",
    "\n",
    "stage_onnx = orig_onnx.replace(ORIG, STAGE)\n",
    "surgery(orig_onnx, stage_onnx, CUT, OUTPUT_LAYER, ACT)\n",
    "print(f\"INPUT: {orig_onnx}\\nCUT {CUT}\\nADD {OUTPUT_LAYER} output layer and {ACT}\\OUTPUT: {stage_onnx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 将onnx文件转换为Caffe\n",
    "from vstk import onnxToCaffe\n",
    "%env GLOG_minloglevel=2\n",
    "stage_prototxt = stage_onnx.replace('onnx', 'prototxt')\n",
    "stage_caffe = stage_onnx.replace('onnx', 'caffemodel')\n",
    "onnxToCaffe(stage_onnx, stage_prototxt, stage_caffe, IMG, S=1, M=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 将Caffe文件转换为VisionSeed可以使用的blob文件\n",
    "from vstk import generateBlob\n",
    "generateBlob(stage_prototxt, nshaves = 2, weights = stage_caffe, ma2480 = True)\n",
    "os.rename('graph', TARGET)\n",
    "print(\"success to generate blob at\", TARGET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载位于./conversion/final/*.blob的模型文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"完成模型训练，撒花~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_py3",
   "language": "python",
   "name": "conda_pytorch_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}